"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.ChainLlm = void 0;
const n8n_workflow_1 = require("n8n-workflow");
const prompts_1 = require("@langchain/core/prompts");
const output_parsers_1 = require("langchain/output_parsers");
const chains_1 = require("langchain/chains");
const messages_1 = require("@langchain/core/messages");
const google_genai_1 = require("@langchain/google-genai");
const ollama_1 = require("@langchain/community/chat_models/ollama");
const sharedFields_1 = require("../../../utils/sharedFields");
const helpers_1 = require("../../../utils/helpers");
const tracing_1 = require("../../../utils/tracing");
async function getImageMessage(context, itemIndex, message) {
    var _a, _b;
    if (message.messageType !== 'imageBinary' && message.messageType !== 'imageUrl') {
        throw new n8n_workflow_1.NodeOperationError(context.getNode(), 'Invalid message type. Only imageBinary and imageUrl are supported');
    }
    const detail = message.imageDetail === 'auto' ? undefined : message.imageDetail;
    if (message.messageType === 'imageUrl' && message.imageUrl) {
        return new messages_1.HumanMessage({
            content: [
                {
                    type: 'image_url',
                    image_url: {
                        url: message.imageUrl,
                        detail,
                    },
                },
            ],
        });
    }
    const binaryDataKey = (_a = message.binaryImageDataKey) !== null && _a !== void 0 ? _a : 'data';
    const inputData = context.getInputData()[itemIndex];
    const binaryData = (_b = inputData.binary) === null || _b === void 0 ? void 0 : _b[binaryDataKey];
    if (!binaryData) {
        throw new n8n_workflow_1.NodeOperationError(context.getNode(), 'No binary data set.');
    }
    const bufferData = await context.helpers.getBinaryDataBuffer(itemIndex, binaryDataKey);
    const model = (await context.getInputConnectionData("ai_languageModel", 0));
    const dataURI = `data:image/jpeg;base64,${bufferData.toString('base64')}`;
    const directUriModels = [google_genai_1.ChatGoogleGenerativeAI, ollama_1.ChatOllama];
    const imageUrl = directUriModels.some((i) => model instanceof i)
        ? dataURI
        : { url: dataURI, detail };
    return new messages_1.HumanMessage({
        content: [
            {
                type: 'image_url',
                image_url: imageUrl,
            },
        ],
    });
}
async function getChainPromptTemplate(context, itemIndex, llm, messages, formatInstructions, query) {
    const queryTemplate = new prompts_1.PromptTemplate({
        template: `{query}${formatInstructions ? '\n{formatInstructions}' : ''}`,
        inputVariables: ['query'],
        partialVariables: formatInstructions ? { formatInstructions } : undefined,
    });
    if ((0, helpers_1.isChatInstance)(llm)) {
        const parsedMessages = await Promise.all((messages !== null && messages !== void 0 ? messages : []).map(async (message) => {
            const messageClass = [
                prompts_1.SystemMessagePromptTemplate,
                prompts_1.AIMessagePromptTemplate,
                prompts_1.HumanMessagePromptTemplate,
            ].find((m) => m.lc_name() === message.type);
            if (!messageClass) {
                throw new n8n_workflow_1.ApplicationError('Invalid message type', {
                    extra: { messageType: message.type },
                });
            }
            if (messageClass === prompts_1.HumanMessagePromptTemplate && message.messageType !== 'text') {
                const test = await getImageMessage(context, itemIndex, message);
                return test;
            }
            const res = messageClass.fromTemplate((message.message || '').replace(/[{}]/g, (match) => match + match));
            return res;
        }));
        const lastMessage = parsedMessages[parsedMessages.length - 1];
        if (lastMessage instanceof messages_1.HumanMessage && Array.isArray(lastMessage.content)) {
            const humanMessage = new prompts_1.HumanMessagePromptTemplate(queryTemplate);
            const test = await humanMessage.format({ query });
            lastMessage.content.push({ text: test.content.toString(), type: 'text' });
        }
        else {
            parsedMessages.push(new prompts_1.HumanMessagePromptTemplate(queryTemplate));
        }
        return prompts_1.ChatPromptTemplate.fromMessages(parsedMessages);
    }
    return queryTemplate;
}
async function createSimpleLLMChain(context, llm, query, prompt) {
    const chain = new chains_1.LLMChain({
        llm,
        prompt,
    }).withConfig((0, tracing_1.getTracingConfig)(context));
    const response = (await chain.invoke({
        query,
        signal: context.getExecutionCancelSignal(),
    }));
    return Array.isArray(response) ? response : [response];
}
async function getChain(context, itemIndex, query, llm, outputParsers, messages) {
    const chatTemplate = await getChainPromptTemplate(context, itemIndex, llm, messages, undefined, query);
    if (!outputParsers.length) {
        return await createSimpleLLMChain(context, llm, query, chatTemplate);
    }
    const combinedOutputParser = outputParsers.length === 1 ? outputParsers[0] : new output_parsers_1.CombiningOutputParser(...outputParsers);
    const formatInstructions = combinedOutputParser.getFormatInstructions();
    const prompt = await getChainPromptTemplate(context, itemIndex, llm, messages, formatInstructions, query);
    const chain = prompt.pipe(llm).pipe(combinedOutputParser);
    const response = (await chain.withConfig((0, tracing_1.getTracingConfig)(context)).invoke({ query }));
    return Array.isArray(response) ? response : [response];
}
function getInputs(parameters) {
    const hasOutputParser = parameters === null || parameters === void 0 ? void 0 : parameters.hasOutputParser;
    const inputs = [
        { displayName: '', type: "main" },
        {
            displayName: 'Model',
            maxConnections: 1,
            type: "ai_languageModel",
            required: true,
        },
    ];
    if (hasOutputParser === undefined || hasOutputParser === true) {
        inputs.push({ displayName: 'Output Parser', type: "ai_outputParser" });
    }
    return inputs;
}
class ChainLlm {
    constructor() {
        this.description = {
            displayName: 'Basic LLM Chain',
            name: 'chainLlm',
            icon: 'fa:link',
            group: ['transform'],
            version: [1, 1.1, 1.2, 1.3, 1.4],
            description: 'A simple chain to prompt a large language model',
            defaults: {
                name: 'Basic LLM Chain',
                color: '#909298',
            },
            codex: {
                alias: ['LangChain'],
                categories: ['AI'],
                subcategories: {
                    AI: ['Chains', 'Root Nodes'],
                },
                resources: {
                    primaryDocumentation: [
                        {
                            url: 'https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.chainllm/',
                        },
                    ],
                },
            },
            inputs: `={{ ((parameter) => { ${getInputs.toString()}; return getInputs(parameter) })($parameter) }}`,
            outputs: ["main"],
            credentials: [],
            properties: [
                (0, sharedFields_1.getTemplateNoticeField)(1978),
                {
                    displayName: 'Prompt',
                    name: 'prompt',
                    type: 'string',
                    required: true,
                    default: '={{ $json.input }}',
                    displayOptions: {
                        show: {
                            '@version': [1],
                        },
                    },
                },
                {
                    displayName: 'Prompt',
                    name: 'prompt',
                    type: 'string',
                    required: true,
                    default: '={{ $json.chat_input }}',
                    displayOptions: {
                        show: {
                            '@version': [1.1, 1.2],
                        },
                    },
                },
                {
                    displayName: 'Prompt',
                    name: 'prompt',
                    type: 'string',
                    required: true,
                    default: '={{ $json.chatInput }}',
                    displayOptions: {
                        show: {
                            '@version': [1.3],
                        },
                    },
                },
                {
                    displayName: 'Prompt',
                    name: 'promptType',
                    type: 'options',
                    options: [
                        {
                            name: 'Take from previous node automatically',
                            value: 'auto',
                            description: 'Looks for an input field called chatInput',
                        },
                        {
                            name: 'Define below',
                            value: 'define',
                            description: 'Use an expression to reference data in previous nodes or enter static text',
                        },
                    ],
                    displayOptions: {
                        hide: {
                            '@version': [1, 1.1, 1.2, 1.3],
                        },
                    },
                    default: 'auto',
                },
                {
                    displayName: 'Text',
                    name: 'text',
                    type: 'string',
                    required: true,
                    default: '',
                    placeholder: 'e.g. Hello, how can you help me?',
                    typeOptions: {
                        rows: 2,
                    },
                    displayOptions: {
                        show: {
                            promptType: ['define'],
                        },
                    },
                },
                {
                    displayName: 'Require Specific Output Format',
                    name: 'hasOutputParser',
                    type: 'boolean',
                    default: false,
                    noDataExpression: true,
                    displayOptions: {
                        hide: {
                            '@version': [1, 1.1, 1.3],
                        },
                    },
                },
                {
                    displayName: 'Chat Messages (if Using a Chat Model)',
                    name: 'messages',
                    type: 'fixedCollection',
                    typeOptions: {
                        multipleValues: true,
                    },
                    default: {},
                    placeholder: 'Add prompt',
                    options: [
                        {
                            name: 'messageValues',
                            displayName: 'Prompt',
                            values: [
                                {
                                    displayName: 'Type Name or ID',
                                    name: 'type',
                                    type: 'options',
                                    options: [
                                        {
                                            name: 'AI',
                                            value: prompts_1.AIMessagePromptTemplate.lc_name(),
                                        },
                                        {
                                            name: 'System',
                                            value: prompts_1.SystemMessagePromptTemplate.lc_name(),
                                        },
                                        {
                                            name: 'User',
                                            value: prompts_1.HumanMessagePromptTemplate.lc_name(),
                                        },
                                    ],
                                    default: prompts_1.SystemMessagePromptTemplate.lc_name(),
                                },
                                {
                                    displayName: 'Message Type',
                                    name: 'messageType',
                                    type: 'options',
                                    displayOptions: {
                                        show: {
                                            type: [prompts_1.HumanMessagePromptTemplate.lc_name()],
                                        },
                                    },
                                    options: [
                                        {
                                            name: 'Text',
                                            value: 'text',
                                            description: 'Simple text message',
                                        },
                                        {
                                            name: 'Image (Binary)',
                                            value: 'imageBinary',
                                            description: 'Process the binary input from the previous node',
                                        },
                                        {
                                            name: 'Image (URL)',
                                            value: 'imageUrl',
                                            description: 'Process the image from the specified URL',
                                        },
                                    ],
                                    default: 'text',
                                },
                                {
                                    displayName: 'Image Data Field Name',
                                    name: 'binaryImageDataKey',
                                    type: 'string',
                                    default: 'data',
                                    required: true,
                                    description: 'The name of the field in the chain’s input that contains the binary image file to be processed',
                                    displayOptions: {
                                        show: {
                                            messageType: ['imageBinary'],
                                        },
                                    },
                                },
                                {
                                    displayName: 'Image URL',
                                    name: 'imageUrl',
                                    type: 'string',
                                    default: '',
                                    required: true,
                                    description: 'URL to the image to be processed',
                                    displayOptions: {
                                        show: {
                                            messageType: ['imageUrl'],
                                        },
                                    },
                                },
                                {
                                    displayName: 'Image Details',
                                    description: 'Control how the model processes the image and generates its textual understanding',
                                    name: 'imageDetail',
                                    type: 'options',
                                    displayOptions: {
                                        show: {
                                            type: [prompts_1.HumanMessagePromptTemplate.lc_name()],
                                            messageType: ['imageBinary', 'imageUrl'],
                                        },
                                    },
                                    options: [
                                        {
                                            name: 'Auto',
                                            value: 'auto',
                                            description: 'Model will use the auto setting which will look at the image input size and decide if it should use the low or high setting',
                                        },
                                        {
                                            name: 'Low',
                                            value: 'low',
                                            description: 'The model will receive a low-res 512px x 512px version of the image, and represent the image with a budget of 65 tokens. This allows the API to return faster responses and consume fewer input tokens for use cases that do not require high detail.',
                                        },
                                        {
                                            name: 'High',
                                            value: 'high',
                                            description: 'Allows the model to see the low res image and then creates detailed crops of input images as 512px squares based on the input image size. Each of the detailed crops uses twice the token budget (65 tokens) for a total of 129 tokens.',
                                        },
                                    ],
                                    default: 'auto',
                                },
                                {
                                    displayName: 'Message',
                                    name: 'message',
                                    type: 'string',
                                    required: true,
                                    displayOptions: {
                                        hide: {
                                            messageType: ['imageBinary', 'imageUrl'],
                                        },
                                    },
                                    default: '',
                                },
                            ],
                        },
                    ],
                },
                {
                    displayName: `Connect an <a data-action='openSelectiveNodeCreator' data-action-parameter-connectiontype='${"ai_outputParser"}'>output parser</a> on the canvas to specify the output format you require`,
                    name: 'notice',
                    type: 'notice',
                    default: '',
                    displayOptions: {
                        show: {
                            hasOutputParser: [true],
                        },
                    },
                },
            ],
        };
    }
    async execute() {
        this.logger.verbose('Executing LLM Chain');
        const items = this.getInputData();
        const returnData = [];
        const llm = (await this.getInputConnectionData("ai_languageModel", 0));
        const outputParsers = await (0, helpers_1.getOptionalOutputParsers)(this);
        for (let itemIndex = 0; itemIndex < items.length; itemIndex++) {
            try {
                let prompt;
                if (this.getNode().typeVersion <= 1.3) {
                    prompt = this.getNodeParameter('prompt', itemIndex);
                }
                else {
                    prompt = (0, helpers_1.getPromptInputByType)({
                        ctx: this,
                        i: itemIndex,
                        inputKey: 'text',
                        promptTypeKey: 'promptType',
                    });
                }
                const messages = this.getNodeParameter('messages.messageValues', itemIndex, []);
                if (prompt === undefined) {
                    throw new n8n_workflow_1.NodeOperationError(this.getNode(), "The 'prompt' parameter is empty.");
                }
                const responses = await getChain(this, itemIndex, prompt, llm, outputParsers, messages);
                responses.forEach((response) => {
                    let data;
                    if (typeof response === 'string') {
                        data = {
                            response: {
                                text: response.trim(),
                            },
                        };
                    }
                    else if (Array.isArray(response)) {
                        data = {
                            data: response,
                        };
                    }
                    else if (response instanceof Object) {
                        data = response;
                    }
                    else {
                        data = {
                            response: {
                                text: response,
                            },
                        };
                    }
                    returnData.push({
                        json: data,
                    });
                });
            }
            catch (error) {
                if (this.continueOnFail(error)) {
                    returnData.push({ json: { error: error.message }, pairedItem: { item: itemIndex } });
                    continue;
                }
                throw error;
            }
        }
        return [returnData];
    }
}
exports.ChainLlm = ChainLlm;
//# sourceMappingURL=ChainLlm.node.js.map