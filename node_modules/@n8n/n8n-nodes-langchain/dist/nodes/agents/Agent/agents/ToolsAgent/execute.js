"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.toolsAgentExecute = void 0;
const n8n_workflow_1 = require("n8n-workflow");
const agents_1 = require("langchain/agents");
const prompts_1 = require("@langchain/core/prompts");
const lodash_1 = require("lodash");
const tools_1 = require("@langchain/core/tools");
const runnables_1 = require("@langchain/core/runnables");
const zod_1 = require("zod");
const output_parsers_1 = require("langchain/output_parsers");
const helpers_1 = require("../../../../../utils/helpers");
const prompt_1 = require("./prompt");
function getOutputParserSchema(outputParser) {
    const parserType = outputParser.lc_namespace[outputParser.lc_namespace.length - 1];
    let schema;
    if (parserType === 'structured') {
        schema = outputParser.schema;
    }
    else if (parserType === 'fix' && outputParser instanceof output_parsers_1.OutputFixingParser) {
        schema = outputParser.parser.schema;
    }
    else {
        schema = zod_1.z.object({ text: zod_1.z.string() });
    }
    return schema;
}
async function toolsAgentExecute() {
    var _a, _b, _c;
    this.logger.verbose('Executing Tools Agent');
    const model = await this.getInputConnectionData("ai_languageModel", 0);
    if (!(0, helpers_1.isChatInstance)(model) || !model.bindTools) {
        throw new n8n_workflow_1.NodeOperationError(this.getNode(), 'Tools Agent requires Chat Model which supports Tools calling');
    }
    const memory = (await this.getInputConnectionData("ai_memory", 0));
    const tools = (await (0, helpers_1.getConnectedTools)(this, true));
    const outputParser = (_a = (await (0, helpers_1.getOptionalOutputParsers)(this))) === null || _a === void 0 ? void 0 : _a[0];
    let structuredOutputParserTool;
    async function agentStepsParser(steps) {
        if (Array.isArray(steps)) {
            const responseParserTool = steps.find((step) => step.tool === 'format_final_response');
            if (responseParserTool) {
                const toolInput = responseParserTool === null || responseParserTool === void 0 ? void 0 : responseParserTool.toolInput;
                const returnValues = (await outputParser.parse(toolInput));
                return {
                    returnValues,
                    log: 'Final response formatted',
                };
            }
        }
        if (outputParser && typeof steps === 'object' && steps.returnValues) {
            const finalResponse = steps.returnValues;
            const returnValues = (await outputParser.parse(finalResponse));
            return {
                returnValues,
                log: 'Final response formatted',
            };
        }
        return steps;
    }
    if (outputParser) {
        const schema = getOutputParserSchema(outputParser);
        structuredOutputParserTool = new tools_1.DynamicStructuredTool({
            schema,
            name: 'format_final_response',
            description: 'Always use this tool for the final output to the user. It validates the output so only use it when you are sure the output is final.',
            func: async () => '',
        });
        tools.push(structuredOutputParserTool);
    }
    const options = this.getNodeParameter('options', 0, {});
    const prompt = prompts_1.ChatPromptTemplate.fromMessages([
        ['system', `{system_message}${outputParser ? '\n\n{formatting_instructions}' : ''}`],
        ['placeholder', '{chat_history}'],
        ['human', '{input}'],
        ['placeholder', '{agent_scratchpad}'],
    ]);
    const agent = (0, agents_1.createToolCallingAgent)({
        llm: model,
        tools,
        prompt,
        streamRunnable: false,
    });
    agent.streamRunnable = false;
    const runnableAgent = runnables_1.RunnableSequence.from([agent, agentStepsParser]);
    const executor = agents_1.AgentExecutor.fromAgentAndTools({
        agent: runnableAgent,
        memory,
        tools,
        returnIntermediateSteps: options.returnIntermediateSteps === true,
        maxIterations: (_b = options.maxIterations) !== null && _b !== void 0 ? _b : 10,
    });
    const returnData = [];
    const items = this.getInputData();
    for (let itemIndex = 0; itemIndex < items.length; itemIndex++) {
        try {
            const input = (0, helpers_1.getPromptInputByType)({
                ctx: this,
                i: itemIndex,
                inputKey: 'text',
                promptTypeKey: 'promptType',
            });
            if (input === undefined) {
                throw new n8n_workflow_1.NodeOperationError(this.getNode(), 'The â€˜text parameter is empty.');
            }
            if (model.lc_namespace.includes('openai') && tools.length === 0) {
                throw new n8n_workflow_1.NodeOperationError(this.getNode(), "Please connect at least one tool. If you don't need any, try the conversational agent instead");
            }
            const response = await executor.invoke({
                input,
                system_message: (_c = options.systemMessage) !== null && _c !== void 0 ? _c : prompt_1.SYSTEM_MESSAGE,
                formatting_instructions: 'IMPORTANT: Always call `format_final_response` to format your final response!',
            });
            returnData.push({
                json: (0, lodash_1.omit)(response, 'system_message', 'formatting_instructions', 'input', 'chat_history', 'agent_scratchpad'),
            });
        }
        catch (error) {
            if (this.continueOnFail(error)) {
                returnData.push({ json: { error: error.message }, pairedItem: { item: itemIndex } });
                continue;
            }
            throw error;
        }
    }
    return [returnData];
}
exports.toolsAgentExecute = toolsAgentExecute;
//# sourceMappingURL=execute.js.map