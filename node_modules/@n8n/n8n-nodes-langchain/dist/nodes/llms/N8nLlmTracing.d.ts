import { BaseCallbackHandler } from '@langchain/core/callbacks/base';
import type { Serialized, SerializedNotImplemented, SerializedSecret } from '@langchain/core/load/serializable';
import type { LLMResult } from '@langchain/core/outputs';
import type { IDataObject, IExecuteFunctions } from 'n8n-workflow';
import { NodeConnectionType } from 'n8n-workflow';
import type { BaseMessage } from '@langchain/core/messages';
import type { SerializedFields } from '@langchain/core/dist/load/map_keys';
type TokensUsageParser = (llmOutput: LLMResult['llmOutput']) => {
    completionTokens: number;
    promptTokens: number;
    totalTokens: number;
};
type LastInput = {
    index: number;
    messages: BaseMessage[] | string[] | string;
    options: SerializedSecret | SerializedNotImplemented | SerializedFields;
};
export declare class N8nLlmTracing extends BaseCallbackHandler {
    name: string;
    executionFunctions: IExecuteFunctions;
    connectionType: NodeConnectionType;
    promptTokensEstimate: number;
    completionTokensEstimate: number;
    lastInput: LastInput;
    options: {
        tokensUsageParser: (llmOutput: LLMResult['llmOutput']) => {
            completionTokens: number;
            promptTokens: number;
            totalTokens: number;
        };
    };
    constructor(executionFunctions: IExecuteFunctions, options?: {
        tokensUsageParser: TokensUsageParser;
    });
    estimateTokensFromGeneration(generations: LLMResult['generations']): Promise<number>;
    estimateTokensFromStringList(list: string[]): Promise<number>;
    handleLLMEnd(output: LLMResult): Promise<void>;
    handleLLMStart(llm: Serialized, prompts: string[]): Promise<void>;
    handleLLMError(error: IDataObject | Error, runId: string, parentRunId?: string | undefined): Promise<void>;
}
export {};
