"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.N8nBinaryLoader = void 0;
const promises_1 = require("stream/promises");
const fs_1 = require("fs");
const n8n_workflow_1 = require("n8n-workflow");
const csv_1 = require("@langchain/community/document_loaders/fs/csv");
const docx_1 = require("@langchain/community/document_loaders/fs/docx");
const json_1 = require("langchain/document_loaders/fs/json");
const pdf_1 = require("@langchain/community/document_loaders/fs/pdf");
const text_1 = require("langchain/document_loaders/fs/text");
const epub_1 = require("@langchain/community/document_loaders/fs/epub");
const tmp_promise_1 = require("tmp-promise");
const helpers_1 = require("./helpers");
const SUPPORTED_MIME_TYPES = {
    auto: ['*/*'],
    pdfLoader: ['application/pdf'],
    csvLoader: ['text/csv'],
    epubLoader: ['application/epub+zip'],
    docxLoader: ['application/vnd.openxmlformats-officedocument.wordprocessingml.document'],
    textLoader: ['text/plain', 'text/mdx', 'text/md'],
    jsonLoader: ['application/json'],
};
class N8nBinaryLoader {
    constructor(context, optionsPrefix = '', binaryDataKey = '', textSplitter) {
        this.context = context;
        this.textSplitter = textSplitter;
        this.optionsPrefix = optionsPrefix;
        this.binaryDataKey = binaryDataKey;
    }
    async processAll(items) {
        const docs = [];
        if (!items)
            return [];
        for (let itemIndex = 0; itemIndex < items.length; itemIndex++) {
            const processedDocuments = await this.processItem(items[itemIndex], itemIndex);
            docs.push(...processedDocuments);
        }
        return docs;
    }
    async processItem(item, itemIndex) {
        const selectedLoader = this.context.getNodeParameter('loader', itemIndex, 'auto');
        const docs = [];
        const metadata = (0, helpers_1.getMetadataFiltersValues)(this.context, itemIndex);
        if (!item)
            return [];
        const binaryData = this.context.helpers.assertBinaryData(itemIndex, this.binaryDataKey);
        const { mimeType } = binaryData;
        if (selectedLoader !== 'auto' && !SUPPORTED_MIME_TYPES[selectedLoader].includes(mimeType)) {
            const neededLoader = Object.keys(SUPPORTED_MIME_TYPES).find((loader) => SUPPORTED_MIME_TYPES[loader].includes(mimeType));
            throw new n8n_workflow_1.NodeOperationError(this.context.getNode(), `Mime type doesn't match selected loader. Please select under "Loader Type": ${neededLoader}`);
        }
        if (!Object.values(SUPPORTED_MIME_TYPES).flat().includes(mimeType)) {
            throw new n8n_workflow_1.NodeOperationError(this.context.getNode(), `Unsupported mime type: ${mimeType}`);
        }
        if (!SUPPORTED_MIME_TYPES[selectedLoader].includes(mimeType) &&
            selectedLoader !== 'textLoader' &&
            selectedLoader !== 'auto') {
            throw new n8n_workflow_1.NodeOperationError(this.context.getNode(), `Unsupported mime type: ${mimeType} for selected loader: ${selectedLoader}`);
        }
        let filePathOrBlob;
        if (binaryData.id) {
            const binaryBuffer = await this.context.helpers.binaryToBuffer(await this.context.helpers.getBinaryStream(binaryData.id));
            filePathOrBlob = new Blob([binaryBuffer], {
                type: mimeType,
            });
        }
        else {
            filePathOrBlob = new Blob([Buffer.from(binaryData.data, n8n_workflow_1.BINARY_ENCODING)], {
                type: mimeType,
            });
        }
        let loader;
        let cleanupTmpFile = undefined;
        switch (mimeType) {
            case 'application/pdf':
                const splitPages = this.context.getNodeParameter(`${this.optionsPrefix}splitPages`, itemIndex, false);
                loader = new pdf_1.PDFLoader(filePathOrBlob, {
                    splitPages,
                });
                break;
            case 'text/csv':
                const column = this.context.getNodeParameter(`${this.optionsPrefix}column`, itemIndex, null);
                const separator = this.context.getNodeParameter(`${this.optionsPrefix}separator`, itemIndex, ',');
                loader = new csv_1.CSVLoader(filePathOrBlob, {
                    column: column !== null && column !== void 0 ? column : undefined,
                    separator,
                });
                break;
            case 'application/epub+zip':
                let filePath;
                if (filePathOrBlob instanceof Blob) {
                    const tmpFileData = await (0, tmp_promise_1.file)({ prefix: 'epub-loader-' });
                    cleanupTmpFile = tmpFileData.cleanup;
                    try {
                        const bufferData = await filePathOrBlob.arrayBuffer();
                        await (0, promises_1.pipeline)([new Uint8Array(bufferData)], (0, fs_1.createWriteStream)(tmpFileData.path));
                        loader = new epub_1.EPubLoader(tmpFileData.path);
                        break;
                    }
                    catch (error) {
                        await cleanupTmpFile();
                        throw new n8n_workflow_1.NodeOperationError(this.context.getNode(), error);
                    }
                }
                else {
                    filePath = filePathOrBlob;
                }
                loader = new epub_1.EPubLoader(filePath);
                break;
            case 'application/vnd.openxmlformats-officedocument.wordprocessingml.document':
                loader = new docx_1.DocxLoader(filePathOrBlob);
                break;
            case 'text/plain':
                loader = new text_1.TextLoader(filePathOrBlob);
                break;
            case 'application/json':
                const pointers = this.context.getNodeParameter(`${this.optionsPrefix}pointers`, itemIndex, '');
                const pointersArray = pointers.split(',').map((pointer) => pointer.trim());
                loader = new json_1.JSONLoader(filePathOrBlob, pointersArray);
                break;
            default:
                loader = new text_1.TextLoader(filePathOrBlob);
        }
        const loadedDoc = this.textSplitter
            ? await this.textSplitter.splitDocuments(await loader.load())
            : await loader.load();
        docs.push(...loadedDoc);
        if (metadata) {
            docs.forEach((document) => {
                document.metadata = {
                    ...document.metadata,
                    ...metadata,
                };
            });
        }
        if (cleanupTmpFile) {
            await cleanupTmpFile();
        }
        return docs;
    }
}
exports.N8nBinaryLoader = N8nBinaryLoader;
//# sourceMappingURL=N8nBinaryLoader.js.map